{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "### 引入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.gfile as gfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义超参数和字符集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definde vals\n",
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "LOWERCASE = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "UPPERCASE = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "CAPTCHA_CHARSET = NUMBER # captcha charset number\n",
    "CAPTCHA_LEN = 4 # captcha length\n",
    "CAPTCHA_HEIGHT = 60 # captcha height\n",
    "CAPTCHA_WIDTH = 160 # captcha width\n",
    "\n",
    "TRAIN_DATASET_DIR = './datas/12/train/'\n",
    "TEST_DATASET_DIR = './datas/12/test/'\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "OPT = 'adam'\n",
    "LOSS = 'binary_crossentropy'\n",
    "\n",
    "MODEL_DIR = './models/16/'\n",
    "MODEL_FORMAT = '.h5'\n",
    "HISTORY_DIR = './history/16/'\n",
    "HISTORY_FORMAT = '.history'\n",
    "\n",
    "filename_str = \"{}captcha_{}_{}_bs_{}_epochs_{}{}\"\n",
    "\n",
    "MODEL_VIS_FILE = './models/16/captcha_classfication.png'\n",
    "MODEL_FILE = filename_str.format(MODEL_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), MODEL_FORMAT)\n",
    "HISTORY_FILE = filename_str.format(HISTORY_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), HISTORY_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义数据处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb to gray\n",
    "def rgb2gray(img):\n",
    "    # y' = 0.299 R + 0.587 G + 0.114 B\n",
    "    # https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale\n",
    "    return np.dot(img[..., :3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot coding\n",
    "def text2vec(text, length=CAPTCHA_LEN, charset=CAPTCHA_CHARSET):\n",
    "    text_len = len(text)\n",
    "    if text_len != length:\n",
    "        raise ValueError('Error: length of captcha should be {}, but got {}'.format(length, text_len))\n",
    "        \n",
    "    # 生成一个形如(CAPTCHA_LEN*CAPTCHA_CHARSET,)的一维向量\n",
    "    # 例如，4个纯数字的验证码生成形如（40*10,）的一维向量\n",
    "    vec = np.zeros(length * len(charset))\n",
    "    for i in range(length):\n",
    "        # one-hot coding\n",
    "        vec[charset.index(text[i]) + i*len(charset)] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels by vector\n",
    "def vec2text(vector):\n",
    "    if not isinstance(vector, np.ndarray):\n",
    "        vector = np.asarray(vector)\n",
    "    vector = np.reshape(vector, [CAPTCHA_LEN, -1])\n",
    "    text = ''\n",
    "    for item in vector:\n",
    "        text += CAPTCHA_CHARSET[np.argmax(item)]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit keras channels\n",
    "def fit_keras_channels(batch, rows=CAPTCHA_HEIGHT, cols=CAPTCHA_WIDTH):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        batch = batch.reshape(batch.shape[0], 1, rows, cols)\n",
    "        input_shape = (1, rows, cols)\n",
    "    else:\n",
    "        batch = batch.reshape(batch.shape[0], rows, cols, 1)\n",
    "        input_shape = (rows, cols, 1)\n",
    "    return batch, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read top100 images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "count = 0\n",
    "for filename in glob.glob(TRAIN_DATASET_DIR + '*.png'):\n",
    "    X_train.append(np.array(Image.open(filename)))\n",
    "    Y_train.append(filename.replace(TRAIN_DATASET_DIR, '', 1).rstrip('.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理训练集图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3294, 60, 160, 1) <class 'numpy.ndarray'>\n",
      "(60, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_train = rgb2gray(X_train)\n",
    "X_train = X_train / 255\n",
    "X_train, input_shape = fit_keras_channels(X_train)\n",
    "\n",
    "print(X_train.shape, type(X_train))\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理训练集标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3294, 40) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Y_train = list(Y_train)\n",
    "\n",
    "for i in range(len(Y_train)):\n",
    "    Y_train[i] = text2vec(Y_train[i])\n",
    "\n",
    "Y_train = np.asarray(Y_train)\n",
    "\n",
    "print(Y_train.shape, type(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取测试集，处理对应图像和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(954, 60, 160, 1) <class 'numpy.ndarray'>\n",
      "(954, 40) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for filename in glob.glob(TEST_DATASET_DIR + '*.png'):\n",
    "    X_test.append(np.array(Image.open(filename)))\n",
    "    Y_test.append(filename.replace(TEST_DATASET_DIR, '', 1).rstrip('.png'))\n",
    "\n",
    "# images\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "X_test = rgb2gray(X_test)\n",
    "X_test = X_test / 255\n",
    "X_test, _ = fit_keras_channels(X_test)\n",
    "\n",
    "# labels\n",
    "Y_test = list(Y_test)\n",
    "for i in range(len(Y_test)):\n",
    "    Y_test[i] = text2vec(Y_test[i])\n",
    "    \n",
    "Y_test = np.asarray(Y_test)\n",
    "\n",
    "print(X_test.shape, type(X_test))\n",
    "print(Y_test.shape, type(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建验证码识别模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs layer\n",
    "inputs = Input(shape=input_shape, name=\"inputs\")\n",
    "\n",
    "# first layer\n",
    "conv1 = Conv2D(32, (3, 3), name=\"conv1\")(inputs)\n",
    "relu1 = Activation('relu', name=\"relu1\")(conv1)\n",
    "\n",
    "# second layer\n",
    "conv2 = Conv2D(32, (3, 3), name=\"conv2\")(relu1)\n",
    "relu2 = Activation('relu', name=\"relu2\")(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), padding='same', name=\"pool2\")(relu2)\n",
    "\n",
    "# third layer\n",
    "conv3 = Conv2D(64, (3, 3), name=\"conv3\")(pool2)\n",
    "relu3 = Activation('relu', name=\"relu3\")(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), padding='same', name=\"pool3\")(relu3)\n",
    "\n",
    "# flatten pooled feature map\n",
    "x = Flatten()(pool3)\n",
    "\n",
    "# Dropout\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# 4个全连接层分别做10分类，分别对应4个字符\n",
    "x = [Dense(10, activation='softmax', name='fc%d'%(i+1))(x) for i in range(4)]\n",
    "\n",
    "# 4个字符向量拼接在一起，与标签向量形式一致，作为模型输出\n",
    "outs = Concatenate()(x)\n",
    "\n",
    "# model\n",
    "model = Model(inputs=inputs, outputs=outs)\n",
    "model.compile(optimizer=OPT, loss=LOSS, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看模型摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 60, 160, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 58, 158, 32)  320         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 58, 158, 32)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 56, 156, 32)  9248        relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 56, 156, 32)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 28, 78, 32)   0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 26, 76, 64)   18496       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu3 (Activation)              (None, 26, 76, 64)   0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 13, 38, 64)   0           relu3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 31616)        0           pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 31616)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 10)           316170      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 10)           316170      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 10)           316170      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 10)           316170      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 40)           0           fc1[0][0]                        \n",
      "                                                                 fc2[0][0]                        \n",
      "                                                                 fc3[0][0]                        \n",
      "                                                                 fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,292,744\n",
      "Trainable params: 1,292,744\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-4bf8615b1cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_VIS_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/repo/venv/py3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repo/venv/py3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repo/venv/py3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=MODEL_VIS_FILE, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3294 samples, validate on 954 samples\n",
      "Epoch 1/10\n",
      " - 55s - loss: 0.3259 - acc: 0.9000 - val_loss: 0.3250 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      " - 55s - loss: 0.3249 - acc: 0.9000 - val_loss: 0.3249 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      " - 62s - loss: 0.3244 - acc: 0.9000 - val_loss: 0.3238 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      " - 58s - loss: 0.3196 - acc: 0.9000 - val_loss: 0.3160 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      " - 67s - loss: 0.2859 - acc: 0.9015 - val_loss: 0.2752 - val_acc: 0.9045\n",
      "Epoch 6/10\n",
      " - 58s - loss: 0.2224 - acc: 0.9171 - val_loss: 0.2373 - val_acc: 0.9140\n",
      "Epoch 7/10\n",
      " - 57s - loss: 0.1754 - acc: 0.9346 - val_loss: 0.2186 - val_acc: 0.9212\n",
      "Epoch 8/10\n",
      " - 55s - loss: 0.1454 - acc: 0.9471 - val_loss: 0.2235 - val_acc: 0.9186\n",
      "Epoch 9/10\n",
      " - 58s - loss: 0.1242 - acc: 0.9549 - val_loss: 0.2248 - val_acc: 0.9215\n",
      "Epoch 10/10\n",
      " - 57s - loss: 0.1053 - acc: 0.9619 - val_loss: 0.2160 - val_acc: 0.9235\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0029\n",
      "0029\n"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "yy = model.predict(X_test[index].reshape(1, 60, 160, 1))\n",
    "print(vec2text(yy))\n",
    "print(vec2text(Y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved trained model at ./models/16/captcha_adam_binary_crossentropy_bs_100_epochs_10.h5\n"
     ]
    }
   ],
   "source": [
    "if not gfile.Exists(MODEL_DIR):\n",
    "    gfile.MakeDirs(MODEL_DIR)\n",
    "\n",
    "model.save(MODEL_FILE)\n",
    "print('saved trained model at %s' % MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存训练过程记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8999999182544192,\n",
       " 0.8999999182544192,\n",
       " 0.8999999182544192,\n",
       " 0.8999999182544192,\n",
       " 0.9015026639719479,\n",
       " 0.9170689041786796,\n",
       " 0.9346159799719986,\n",
       " 0.9470552593270576,\n",
       " 0.9549408211589366,\n",
       " 0.9618852456989763]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gfile.Exists(HISTORY_DIR) == False:\n",
    "    gfile.MakeDirs(HISTORY_DIR)\n",
    "\n",
    "with open(HISTORY_FILE, 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
