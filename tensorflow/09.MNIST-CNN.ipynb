{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN\n",
    "\n",
    "### CNN简介\n",
    "\n",
    "CNN模型是一种以卷积为核心的前馈神经网络模型。20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（ConvoluTlonal Neural Networks, 简称CNN）。\n",
    "\n",
    "<img width=80% height=80% src=\"imgs/09/01.png\" alt=\"imgs/09/01.png\" title=\"图1\" />\n",
    "\n",
    "### 卷积（Convolution）\n",
    "\n",
    "卷积是分析数学中的一种基础运算，其中对输入数据做运算时所用到的函数称为卷积核。设：$f(x), g(x)$是$R$上的两个可积函数，做积分：\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} f(\\tau)g(x-\\tau){\\rm d}\\tau $$\n",
    "\n",
    "可以证明，关于几乎所有的实数$x$，上述积分是存在的。这样，随着$x$的不同取值，这个积分就定义了一个如下的新函数，称为函数$f$与$g$的卷积。\n",
    "\n",
    "$$(f*g)(t) \\stackrel{def}= \\int_{\\mathbb{R^n}} f(\\tau)g(t-\\tau){\\rm d}\\tau $$\n",
    "\n",
    "<img width=80% height=80% src=\"imgs/09/02.gif\" alt=\"imgs/09/02.gif\" title=\"图2\" />\n",
    "\n",
    "### 卷积层（Convolutional Layer，conv）\n",
    "\n",
    "卷积层是使用一系列卷积核与多通道输入数据做卷积的线性计算层。卷积层的提出是为了利用输入数据（如图像）中特征的局域性和位置无关性来降低整个模型的参数量。卷积运算过程与图像处理算法中常用的空间滤波是类似的。因此，卷积常常被通俗地理解为一种“滤波”过程，卷积核与输入数据作用之后得到了“滤波”后的图像，从而提取出了图像的特征。\n",
    "\n",
    "| <img width=85% height=85% src=\"imgs/09/03.gif\" alt=\"imgs/09/03.gif\" title=\"图3\" /> | <img width=75% height=75% src=\"imgs/09/04.png\" alt=\"imgs/09/04.png\" title=\"图4\" /> |\n",
    "| :---- | :---- |\n",
    "\n",
    "### 池化层（Pooling）\n",
    "\n",
    "池化层是用于缩小数据规模的一种非线性计算层。为了降低特征纬度，我们需要对输入数据进行采样，具体做法是在一个或者多个卷积层后增加一个池化层。池化层由三个参数决定：（1）池化类型，一般有最大池化和平均池化两种；（2）池化核的大小 k；（3）池化核的滑动间隔 s。下图给出了一种池化层的示例。其中，$2\\times2$ 大小的池化窗口以2个单位距离在输入数据上滑动。在池化层中，如果采用最大池化类型，则输出为输入窗口内四个值的最大值；如采用平均池化类型，则输出为输入窗口内四个值的平均值。\n",
    "\n",
    "<img width=50% height=50% src=\"imgs/09/05.png\" alt=\"imgs/09/05.png\" title=\"图5\" />\n",
    "\n",
    "### Dropput层\n",
    "\n",
    "Dropout是常用的一种正则化方法，Dropout层是一种正则化层。全连接层参数量非常庞大（占据量CNN模型参数量的80% ～ 90%左右），发生过拟合问题的风险比较高，所以我们通常需要一些正则化方法训练带有全连接层的CNN模型。在每次迭代训练时，将神经元以一定的概率值暂时随机丢弃，即在当前迭代中不参与训练。\n",
    "\n",
    "<img width=60% height=60% src=\"imgs/09/06.png\" alt=\"imgs/09/06.png\" title=\"图6\" />\n",
    "\n",
    "### Flatten\n",
    "\n",
    "将卷积和池化后提取的特征摊平后输入全连接网络，这里与MNIST softmax网络的输入层类似。MNIST CNN输入特征，MNIST Softmax输入原图。\n",
    "\n",
    "<img width=60% height=60% src=\"imgs/09/07.png\" alt=\"imgs/09/07.png\" title=\"图7\" />\n",
    "\n",
    "<img width=70% height=70% src=\"imgs/09/08.png\" alt=\"imgs/09/08.png\" title=\"图8\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
